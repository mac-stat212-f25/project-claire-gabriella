---
title: "msg"
format: html
---

High scores are given to words that are frequent in a single document (high TF) but rare in the overall corpus (high IDF). These words are often considered the most important or "telling" words for that document. 
Low TF-IDF scores are given to words that are either not very frequent in the document or are very common across all documents. 


```{r eval=FALSE}
library(readr)
library(stringr)
library(dplyr)
library(lubridate)
library(tidytext)
library(ggplot2)

df <- readRDS("../data/processed/ethan.rds")

df <- df %>%
  mutate(
    date = ymd_hms(date),
    year  = year(date),
    month = month(date),
    day   = day(date),
    time  = format(date, "%H:%M:%S")
  )

df$id <- 1:nrow(df)

word_counts <- df %>%
  unnest_tokens(word, text) %>% 
  count(id, word, sort = TRUE)

word_counts <- word_counts %>%
  bind_tf_idf(term = word, document = id, n)

word_counts <- word_counts |> 
  filter(str_length(word) > 5)

word_counts %>% 
  slice_max(tf_idf, n = 15) %>% 
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(tf_idf, word)) +
  geom_col(show.legend = FALSE) +
  labs(x = "tf-idf", y = NULL) 
```

```{r eval=FALSE}
df$id <- seq_len(nrow(df))   
tfidf <- df %>%
  unnest_tokens(word, text) %>%
  count(id, word) %>%
  bind_tf_idf(word, id, n)
df_joined <- df %>%
  left_join(tfidf %>% group_by(id) %>% summarise(tfidf = list(cur_data_all())),
            by = "id")
df_tidy <- df %>% left_join(tfidf, by = "id")
```


```{r}
library(dplyr)
library(tidytext)

# Display the top 5 terms for each document
top_terms_by_doc <- df_tidy |>
  group_by(id) |>
  slice_max(order_by = tf_idf, n = 5) |>
  ungroup() |>
  arrange(id, desc(tf_idf))

print(top_terms_by_doc)

# Calculate the total TF-IDF score for each term
overall_top_terms <- tidy_tfidf |>
  group_by(term) |>
  summarise(total_tfidf = sum(value)) |>
  arrange(desc(total_tfidf))

# Display the top 20
head(overall_top_terms, 20)

library(ggplot2)

# Create a bar plot of the top 15 overall terms
overall_top_terms |>
  top_n(15, total_tfidf) |>
  ggplot(aes(x = reorder(term, total_tfidf), y = total_tfidf)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 15 Terms by Total TF-IDF Score", x = "Term", y = "Total TF-IDF")

library(wordcloud)

# Convert the overall top terms data to a frequency table
word_freq <- setNames(overall_top_terms$total_tfidf, overall_top_terms$term)

# Plot the word cloud
wordcloud(
  words = names(word_freq),
  freq = word_freq,
  max.words = 100, # Adjust for better display
  random.order = FALSE,
  colors = brewer.pal(8, "Dark2") # Use a color palette
)

# Example for a subset: Top 20 terms across 5 documents
top_terms_for_plot <- tidy_tfidf |>
  filter(document %in% unique(tidy_tfidf$document)[1:5]) |> # Select first 5 documents
  filter(term %in% overall_top_terms$term[1:20]) # Select top 20 overall terms

ggplot(top_terms_for_plot, aes(x = term, y = document, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(fill = "TF-IDF Score")
```


